from llama_index.core.retrievers import VectorIndexRetriever

def delete_document(file_name: str, vector_store, summary_store):
    """
    Delete all embeddings and summary embeddings for a document.
    Matches based on file_name metadata.
    """
    print(f"üóëÔ∏è Deleting document '{file_name}' from Risklab stores...")

    # Build temporary retrievers from the live indexes
    vector_index = VectorStoreIndex.from_vector_store(vector_store)
    summary_index = VectorStoreIndex.from_vector_store(summary_store)

    vector_retriever = VectorIndexRetriever(index=vector_index, similarity_top_k=50)
    summary_retriever = VectorIndexRetriever(index=summary_index, similarity_top_k=50)

    deleted_vector = 0
    deleted_summary = 0

    # Step 1Ô∏è‚É£ Retrieve nodes from vector store
    results = vector_retriever.retrieve(file_name)
    for r in results:
        try:
            vector_store.delete(ref_doc_id=r.node.id_)
            deleted_vector += 1
        except Exception as e:
            print(f"‚ö†Ô∏è Failed to delete vector node {r.node.id_}: {e}")

    # Step 2Ô∏è‚É£ Retrieve nodes from summary store
    results = summary_retriever.retrieve(file_name)
    for r in results:
        try:
            summary_store.delete(ref_doc_id=r.node.id_)
            deleted_summary += 1
        except Exception as e:
            print(f"‚ö†Ô∏è Failed to delete summary node {r.node.id_}: {e}")

    print(f"‚úÖ Deleted {deleted_vector} vector nodes and {deleted_summary} summary nodes for '{file_name}'.")
    return deleted_vector, deleted_summary
